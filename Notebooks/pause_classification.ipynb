{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from psutil import *\n",
    "# # This code will return the number of CPU\n",
    "# print(\"Number of CPU: \", cpu_count())\n",
    "# # This code will return the CPU info\n",
    "# !cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install aeon\n",
    "# %pip install tsfresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from aeon.classification.convolution_based import RocketClassifier\n",
    "from aeon.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from aeon.classification.feature_based import FreshPRINCEClassifier\n",
    "from aeon.classification.interval_based import RSTSF\n",
    "from aeon.classification.shapelet_based import RDSTClassifier\n",
    "from aeon.classification.dictionary_based import MUSE\n",
    "from aeon.classification.convolution_based import MultiRocketHydraClassifier\n",
    "from aeon.classification.deep_learning import InceptionTimeClassifier\n",
    "from aeon.classification.hybrid import HIVECOTEV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# for fn in uploaded.keys():\n",
    "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "#       name=fn, length=len(uploaded[fn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 28\n",
    "WINDOW_STRIDE = 9\n",
    "# HALF_MOV_TIME = (130/2) * 52\n",
    "\n",
    "MOVEMENT_SPECIFIC_MODEL = True\n",
    "\n",
    "# Use the same number of windows for each movement\n",
    "SAME_WINDOW_COUNT = True\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"../data/*.csv\")\n",
    "# files = glob.glob(\"*.csv\")\n",
    "\n",
    "# list of dataframes\n",
    "dataframes = []\n",
    "\n",
    "for f in files:\n",
    "    dataframes.append(pd.read_csv(f))\n",
    "\n",
    "# df = pd.read_csv(\"../data/20221115_100424.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_all_movements = [[],[],[],[],[],[],[],[],[],[]]\n",
    "labels_all_movements = [[],[],[],[],[],[],[],[],[],[]]\n",
    "groups_all_movements = [[],[],[],[],[],[],[],[],[],[]]\n",
    "windows_all_movements_balanced = [[],[],[],[],[],[],[],[],[],[]]\n",
    "labels_all_movements_balanced = [[],[],[],[],[],[],[],[],[],[]]\n",
    "groups_all_movements_balanced = [[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "total_windows = 0\n",
    "non_rep_windows_before = 0\n",
    "non_rep_windows_after = 0\n",
    "\n",
    "movement_index_map = {\n",
    "    'Jalka sivulle oikea': 0,\n",
    "    'Jalka sivulle vasen': 1,\n",
    "    'Jalka taakse oikea': 2,\n",
    "    'Jalka taakse vasen': 3,\n",
    "    'Jalkanosto oikea': 4,\n",
    "    'Jalkanosto vasen': 5,\n",
    "    'Polvinosto oikea': 6,\n",
    "    'Polvinosto vasen': 7,\n",
    "    'Seiso ylös': 8,\n",
    "    'Varpaille': 9,\n",
    "}\n",
    "\n",
    "for index, df in enumerate(dataframes):\n",
    "\n",
    "    df = df[~df.Movement.isin(['Start calibration', 'End calibration', 'Not movement', 'Not movement inactive', 'Not movement active', 'Seiso ylös sensor vaihto'])]\n",
    "    if not df.empty: # Check if needed\n",
    "        sensor_placement_groups = df.groupby('SensorPlacement')\n",
    "        left_sensor_df = sensor_placement_groups.get_group('left').copy()\n",
    "        right_sensor_df = sensor_placement_groups.get_group('right').copy()\n",
    "\n",
    "        left_movement_groups = left_sensor_df.groupby(\"Movement\", sort=False)\n",
    "        right_movement_groups = right_sensor_df.groupby(\"Movement\", sort=False)\n",
    "\n",
    "        for group_name, left_df in left_movement_groups:\n",
    "            right_df = right_movement_groups.get_group(group_name)\n",
    "            # The data is recorded for each sensor separately. We want all measurements from all sensors at a single timestep insted\n",
    "            # This is done by separating data from different sensors and renaming those columns before combining the data on the closest common timestep\n",
    "            # There is not data from all sensors on the exact same timestep\n",
    "\n",
    "            # placement_groups = group_df.groupby(\"SensorPlacement\")\n",
    "            # left_df = placement_groups.get_group('left')\n",
    "\n",
    "            # Sorting is required by merge_asof later\n",
    "            left_df = left_df.sort_values(by=['Timestamp'])\n",
    "            right_df = right_df.sort_values(by=['Timestamp'])\n",
    "\n",
    "            # Movement and Start are dropped on the right dataframe because the data \n",
    "            # will be combined with the data from the left sensor on the closest timestep.\n",
    "            # We do not want to duplicate this data from both sensors\n",
    "\n",
    "            # drop columns that are not needed and rename remaining\n",
    "            left_df.drop(['SensorPlacement', 'MagnX', 'MagnY', 'MagnZ'], axis=1, inplace=True)\n",
    "            left_df.rename(columns = {'AccX':'lax', 'AccY':'lay', 'AccZ':'laz', 'GyroX':'lgx', 'GyroY':'lgy', 'GyroZ':'lgz'}, inplace = True)\n",
    "\n",
    "            right_df.drop(['Movement', 'SensorPlacement', 'Start', 'MagnX', 'MagnY', 'MagnZ'], axis=1, inplace=True)\n",
    "            right_df.rename(columns = {'AccX':'rax', 'AccY':'ray', 'AccZ':'raz', 'GyroX':'rgx', 'GyroY':'rgy', 'GyroZ':'rgz',}, inplace = True)\n",
    "\n",
    "            # combine left and right sensor dataframes on the nearest timestamp using left-join\n",
    "            combined_df = pd.merge_asof(left_df, right_df, on='Timestamp', direction='nearest')\n",
    "\n",
    "\n",
    "            # remove all rows before and including the first and after and including the last movement start indicator\n",
    "            # this removes bad data that is added at the start and end of recording sessions\n",
    "            # also removes the last movement but there is no end movement indicator\n",
    "            start_df = combined_df[combined_df[\"Start\"] == 1]\n",
    "\n",
    "            # debug\n",
    "            if start_df.empty:\n",
    "                print(group_name)\n",
    "\n",
    "            combined_df = combined_df.loc[(combined_df[\"Timestamp\"] > start_df.iloc[0,0]-1000) & (combined_df[\"Timestamp\"] < start_df.iloc[-1, 0]-500), :]\n",
    "\n",
    "            all_windows = []\n",
    "            all_labels = []\n",
    "            # all_groups = []\n",
    "\n",
    "            balanced_windows = []\n",
    "            balanced_labels = []\n",
    "            balanced_groups = []\n",
    "\n",
    "            # movement_name_list.append(group_name)\n",
    "            # add map from group name to index nr in movement_name_list\n",
    "            # movement_index_map[group_name] = len(movement_index_map)\n",
    "            # windows_all_movements.append(windows)\n",
    "            # labels_all_movements.append(labels)\n",
    "\n",
    "            for i in range(0, len(combined_df) - WINDOW_SIZE, WINDOW_STRIDE):\n",
    "                window_df = combined_df.iloc[i:i+WINDOW_SIZE].copy()\n",
    "                all_labels.append(window_df['Start'].values.max())\n",
    "                # all_groups.append(index)\n",
    "                window_df.drop(['Timestamp', 'Start', 'Movement'], axis=1, inplace=True)\n",
    "                window_df = window_df.T\n",
    "                all_windows.append(window_df.values.tolist())\n",
    "            \n",
    "            if SAME_WINDOW_COUNT:\n",
    "                total_windows += len(all_windows)\n",
    "\n",
    "                all_movement_repetitions = []\n",
    "                all_movement_non_repetitions = []\n",
    "                \n",
    "                for i in range(len(all_windows)):\n",
    "                    if all_labels[i] == 1:\n",
    "                        all_movement_repetitions.append(all_windows[i])\n",
    "                    else:\n",
    "                        all_movement_non_repetitions.append(all_windows[i])\n",
    "                \n",
    "                non_rep_windows_before += len(all_movement_non_repetitions)\n",
    "                \n",
    "                all_movement_non_repetitions = random.sample(all_movement_non_repetitions, len(all_movement_repetitions))\n",
    "                non_rep_windows_after += len(all_movement_non_repetitions)\n",
    "\n",
    "                listofzeros = [0] * len(all_movement_non_repetitions)\n",
    "                listofones = [1] * len(all_movement_repetitions)\n",
    "\n",
    "                balanced_windows = all_movement_non_repetitions\n",
    "                balanced_labels = listofzeros\n",
    "\n",
    "                balanced_windows.extend(all_movement_repetitions)\n",
    "                balanced_labels.extend(listofones)\n",
    "\n",
    "                z = list(zip(balanced_windows, balanced_labels))\n",
    "\n",
    "                random.shuffle(z)\n",
    "\n",
    "                balanced_windows, balanced_labels = zip(*z)\n",
    "                balanced_windows = list(balanced_windows)\n",
    "                balanced_labels = list(balanced_labels)\n",
    "                balanced_groups = [index] * len(balanced_windows)\n",
    "\n",
    "\n",
    "            windows_all_movements[movement_index_map[group_name]].append(all_windows)\n",
    "            labels_all_movements[movement_index_map[group_name]].append(all_labels)\n",
    "            # groups_all_movements[movement_index_map[group_name]].extend(all_groups)\n",
    "\n",
    "            windows_all_movements_balanced[movement_index_map[group_name]].extend(balanced_windows)\n",
    "            labels_all_movements_balanced[movement_index_map[group_name]].extend(balanced_labels)\n",
    "            groups_all_movements_balanced[movement_index_map[group_name]].extend(balanced_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total window count: 18482, non repetition windows before: 15397, non repetition windows after: 3085\n"
     ]
    }
   ],
   "source": [
    "print(f'Total window count: {total_windows}, non repetition windows before: {non_rep_windows_before}, non repetition windows after: {non_rep_windows_after}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movement 0 complete\n",
      "Movement 1 complete\n",
      "Movement 2 complete\n",
      "Movement 3 complete\n",
      "Movement 4 complete\n",
      "Movement 5 complete\n",
      "Movement 6 complete\n",
      "Movement 7 complete\n",
      "Movement 8 complete\n",
      "Movement 9 complete\n"
     ]
    }
   ],
   "source": [
    "if MOVEMENT_SPECIFIC_MODEL:\n",
    "    test_labels_all_movements = [[],[],[],[],[],[],[],[],[],[]]\n",
    "    predictions_all_movements = [[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "    data_list = []\n",
    "    test_labels_balanced = np.array([])\n",
    "    predictions_balanced = np.array([])\n",
    "    test_labels_all = np.array([])\n",
    "    predictions_all = np.array([])\n",
    "\n",
    "    test_labels_per_movement = [[],[],[],[],[],[],[],[],[],[]]\n",
    "    predictions_per_movement = [[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "    for index, windows in enumerate(windows_all_movements_balanced):\n",
    "        labels = labels_all_movements_balanced[index]\n",
    "        groups = groups_all_movements_balanced[index]\n",
    "\n",
    "        logo = LeaveOneGroupOut()\n",
    "\n",
    "        group_index = 0\n",
    "        for train, test in logo.split(windows, labels, groups=groups):\n",
    "\n",
    "            train_x = np.take(windows, train, 0)\n",
    "            train_y = np.take(labels, train, 0)\n",
    "            test_x = np.take(windows, test, 0)\n",
    "            test_y = np.take(labels, test, 0)\n",
    "\n",
    "            classifier = RocketClassifier(n_jobs=-1)\n",
    "            # classifier = RDSTClassifier(n_jobs=-1)\n",
    "            # classifier = MultiRocketHydraClassifier(n_jobs=-1)\n",
    "            # classifier = KNeighborsTimeSeriesClassifier(n_jobs=-1)\n",
    "            # classifier = RSTSF(n_jobs=-1)\n",
    "            # classifier = MUSE(n_jobs=-1)\n",
    "            # classifier = FreshPRINCEClassifier(n_jobs=-1)\n",
    "            # classifier = HIVECOTEV2(n_jobs=-1)\n",
    "            # classifier = InceptionTimeClassifier()\n",
    "\n",
    "            fit_time = 0\n",
    "            predict_time = 0\n",
    "\n",
    "            t0 = time.perf_counter()\n",
    "            classifier.fit(train_x, train_y)\n",
    "            t1 = time.perf_counter()\n",
    "            fit_time = t1-t0\n",
    "\n",
    "            t0 = time.perf_counter()\n",
    "            y_pred = classifier.predict(test_x)\n",
    "            t1 = time.perf_counter()\n",
    "            predict_time = t1-t0\n",
    "\n",
    "            accuracy = accuracy_score(test_y, y_pred)\n",
    "            f1 = f1_score(test_y, y_pred)\n",
    "            # macro = f1_score(test_y, y_pred, average='macro')\n",
    "            # micro = f1_score(test_y, y_pred, average='micro')\n",
    "            # weighted = f1_score(test_y, y_pred, average='weighted')\n",
    "            # none = f1_score(test_y, y_pred, average=None)\n",
    "            \n",
    "            # print(score)\n",
    "            row = [index, accuracy, f1, fit_time, predict_time]\n",
    "            data_list.append(row)\n",
    "\n",
    "            test_labels_balanced = np.concatenate((test_labels_balanced, test_y))\n",
    "            predictions_balanced = np.concatenate((predictions_balanced, y_pred))\n",
    "\n",
    "            test_labels_per_movement[index].extend(test_y.tolist())\n",
    "            predictions_per_movement[index].extend(y_pred.tolist())\n",
    "\n",
    "            # For all windows\n",
    "            test_x_all_windows = np.array(windows_all_movements[index][group_index])\n",
    "            test_y_all_windows = np.array(labels_all_movements[index][group_index])\n",
    "            y_pred_all_windows = classifier.predict(test_x_all_windows)\n",
    "            accuracy_all_windows = accuracy_score(test_y_all_windows, y_pred_all_windows)\n",
    "\n",
    "            # test_labels_all = np.concatenate((test_labels_all, test_y_all_windows))\n",
    "            # predictions_all = np.concatenate((predictions_all, y_pred_all_windows))\n",
    "\n",
    "            # Save labels and predictions for post processing in 2d array\n",
    "\n",
    "            test_labels_all_movements[index].append(test_y_all_windows.tolist())\n",
    "            predictions_all_movements[index].append(y_pred_all_windows.tolist())\n",
    "\n",
    "            group_index += 1\n",
    "\n",
    "        print(f\"Movement {index} complete\")\n",
    "\n",
    "    result_df = pd.DataFrame(data_list, columns =['index', 'accuracy', 'f1', 'fit_time', 'predict_time']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index  accuracy        f1  fit_time  predict_time\n",
      "0       0  0.850000  0.857143  2.978770      0.328014\n",
      "1       0  0.903226  0.906250  2.715624      0.353985\n",
      "2       0  0.816667  0.825397  2.713192      0.332090\n",
      "3       0  0.766667  0.781250  3.432882      0.388187\n",
      "4       0  0.866667  0.851852  3.914219      0.474324\n",
      "..    ...       ...       ...       ...           ...\n",
      "95      9  0.935484  0.935484  3.032344      0.374249\n",
      "96      9  0.900000  0.903226  3.062647      0.381965\n",
      "97      9  0.816667  0.800000  3.065967      0.405452\n",
      "98      9  0.900000  0.900000  3.198472      0.367466\n",
      "99      9  0.983871  0.983607  3.695051      0.422726\n",
      "\n",
      "[100 rows x 5 columns]\n",
      "Total accuracy: 0.8711507293354943, Total f1: 0.8686601685114819, Min accuracy: 0.6515151515151515, Max accuracy: 0.9838709677419355, STD accuracy: 0.06806995976087013 Total fit time: 340.0658154490375, Total predict time: 41.8972977999656\n"
     ]
    }
   ],
   "source": [
    "if MOVEMENT_SPECIFIC_MODEL:\n",
    "    print(result_df)\n",
    "    tot_accuaracy = accuracy_score(test_labels_balanced, predictions_balanced)\n",
    "    tot_f1 = f1_score(test_labels_balanced, predictions_balanced)\n",
    "    print(f\"Total accuracy: {tot_accuaracy}, Total f1: {tot_f1}, Min accuracy: {result_df['accuracy'].min()}, Max accuracy: {result_df['accuracy'].max()}, STD accuracy: {result_df['accuracy'].std()} Total fit time: {result_df['fit_time'].sum()}, Total predict time: {result_df['predict_time'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.871129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.860323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.876495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.895548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.906122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.883226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.877017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.798740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.884624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy\n",
       "index          \n",
       "0      0.871129\n",
       "1      0.860323\n",
       "2      0.876495\n",
       "3      0.861119\n",
       "4      0.895548\n",
       "5      0.906122\n",
       "6      0.883226\n",
       "7      0.877017\n",
       "8      0.798740\n",
       "9      0.884624"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[[\"index\",\"accuracy\"]].groupby(\"index\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_per_movement = []\n",
    "\n",
    "for i in range(10):\n",
    "    accuracy_score_per_movement.append(accuracy_score(test_labels_per_movement[i], predictions_per_movement[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.872168284789644,\n",
       " 0.860655737704918,\n",
       " 0.8762214983713354,\n",
       " 0.8598726114649682,\n",
       " 0.8957654723127035,\n",
       " 0.9061488673139159,\n",
       " 0.8831168831168831,\n",
       " 0.8770226537216829,\n",
       " 0.7971246006389776,\n",
       " 0.8848684210526315]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score_per_movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 80, One off: 9, Two off: 4, More off: 7\n"
     ]
    }
   ],
   "source": [
    "BEGINNING_ZERO = 2\n",
    "END_ZERO = 2\n",
    "\n",
    "correct = 0\n",
    "one_off = 0\n",
    "two_off = 0\n",
    "more_off = 0\n",
    "\n",
    "def flip_small_prediction_groups(group_df, min_size):\n",
    "    # Small groups are skipped\n",
    "    if group_df['Prediction'].count() <= min_size:\n",
    "        # Get the predicted value\n",
    "        # Flip all prediction values\n",
    "        group_df['Prediction'] = group_df['Prediction'].replace({0:1, 1:0})\n",
    "        return group_df\n",
    "    else:\n",
    "        return group_df\n",
    "\n",
    "def flip_small_zero_groups(group_df, min_size):\n",
    "    # Small groups are skipped\n",
    "    if group_df['Prediction'].count() <= min_size:\n",
    "        if group_df['Prediction'].iloc[0] == 0:\n",
    "            # Get the predicted value\n",
    "            # Flip all prediction values\n",
    "            group_df['Prediction'] = group_df['Prediction'].replace({0:1, 1:0})\n",
    "            return group_df\n",
    "        else:\n",
    "            return group_df\n",
    "    else:\n",
    "        return group_df\n",
    "\n",
    "def get_group_middle(group_df):\n",
    "    new_column =  [0] * len(group_df.index)\n",
    "    group_df['Pause middle'] = new_column\n",
    "    if group_df['Prediction'].iloc[0] == 1:\n",
    "        group_df.iat[int(len(group_df.index) / 2), 3] = 1\n",
    "        return group_df\n",
    "    else:\n",
    "        return group_df\n",
    "\n",
    "for movement in range(10):\n",
    "    for person in range(10):\n",
    "        a = test_labels_all_movements[movement][person]\n",
    "        b = predictions_all_movements[movement][person]\n",
    "\n",
    "        # a = test_labels_all_movements[3][1]\n",
    "        # b = predictions_all_movements[3][1]\n",
    "\n",
    "        pause_prediction_df = pd.DataFrame({'Label': a, 'Original prediction': b})\n",
    "        pause_prediction_df['Prediction'] = pause_prediction_df['Original prediction']\n",
    "\n",
    "        pause_prediction_df.iloc[0:BEGINNING_ZERO, -1] = 0\n",
    "        pause_prediction_df.iloc[-END_ZERO:, -1] = 0\n",
    "\n",
    "        # group into groups of either pauses or non pauses\n",
    "        groups = pause_prediction_df.groupby((pause_prediction_df['Prediction'] != pause_prediction_df['Prediction'].shift()).cumsum(), group_keys=False)\n",
    "        # Flip value of prediction\n",
    "        pause_prediction_df = groups.apply(flip_small_prediction_groups, min_size=1)\n",
    "\n",
    "        # Remove groups of 2 or 3 zeros\n",
    "        groups = pause_prediction_df.groupby((pause_prediction_df['Prediction'] != pause_prediction_df['Prediction'].shift()).cumsum(), group_keys=False)\n",
    "        pause_prediction_df = groups.apply(flip_small_zero_groups, min_size=5)\n",
    "\n",
    "        #middle\n",
    "        groups = pause_prediction_df.groupby((pause_prediction_df['Prediction'] != pause_prediction_df['Prediction'].shift()).cumsum(), group_keys=False)\n",
    "        pause_prediction_df = groups.apply(get_group_middle)\n",
    "\n",
    "        pause_count = pause_prediction_df['Pause middle'].sum()\n",
    "\n",
    "        if pause_count == 10:\n",
    "            correct += 1\n",
    "        elif pause_count == 9 or pause_count == 11:\n",
    "            one_off += 1\n",
    "        elif pause_count == 8 or pause_count == 12:\n",
    "            two_off += 1\n",
    "        else:\n",
    "            more_off += 1\n",
    "        \n",
    "print(f\"Correct: {correct}, One off: {one_off}, Two off: {two_off}, More off: {more_off}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not same window count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not movement specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not MOVEMENT_SPECIFIC_MODEL:\n",
    "    test_labels = np.array([])\n",
    "    predictions = np.array([])\n",
    "\n",
    "    all_windows = []\n",
    "    all_labels = []\n",
    "    all_groups = []\n",
    "    data_list = []\n",
    "\n",
    "    for movement_windows in windows_all_movements:\n",
    "        all_windows.extend(movement_windows)\n",
    "\n",
    "    for movement_labels in labels_all_movements:\n",
    "        all_labels.extend(movement_labels)\n",
    "\n",
    "    for movement_groups in groups_all_movements:\n",
    "        all_groups.extend(movement_groups)\n",
    "\n",
    "    # Not efficient, should use lists\n",
    "    test_labels = np.array([])\n",
    "    predictions = np.array([])\n",
    "    all_scores = []\n",
    "\n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    for train, test in logo.split(all_windows, all_labels, groups=all_groups):\n",
    "\n",
    "        train_x = np.take(all_windows, train, 0)\n",
    "        train_y = np.take(all_labels, train, 0)\n",
    "        test_x = np.take(all_windows, test, 0)\n",
    "        test_y = np.take(all_labels, test, 0)\n",
    "\n",
    "        classifier = RocketClassifier(n_jobs=8)\n",
    "        # classifier = KNeighborsTimeSeriesClassifier(n_jobs=8)\n",
    "        # classifier = FreshPRINCEClassifier(n_jobs=8)\n",
    "        # classifier = RSTSF(n_jobs=8)\n",
    "        # classifier = RDSTClassifier(n_jobs=8)\n",
    "        # classifier = MUSE(n_jobs=8)\n",
    "        # classifier = MultiRocketHydraClassifier(n_jobs=8)\n",
    "        # classifier = InceptionTimeClassifier()\n",
    "        # classifier = HIVECOTEV2(n_jobs=8)\n",
    "\n",
    "        fit_time = 0\n",
    "        predict_time = 0\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        classifier.fit(train_x, train_y)\n",
    "        t1 = time.perf_counter()\n",
    "        fit_time = t1-t0\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        y_pred = classifier.predict(test_x)\n",
    "        t1 = time.perf_counter()\n",
    "        predict_time = t1-t0\n",
    "\n",
    "        accuracy = accuracy_score(test_y, y_pred)\n",
    "        \n",
    "        # print(score)\n",
    "        row = [accuracy, fit_time, predict_time]\n",
    "        data_list.append(row)\n",
    "        \n",
    "        test_labels = np.concatenate((test_labels, test_y))\n",
    "        predictions = np.concatenate((predictions, y_pred))\n",
    "\n",
    "    \n",
    "    result_df = pd.DataFrame(data_list, columns =['accuracy', 'fit_time', 'predict_time']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not MOVEMENT_SPECIFIC_MODEL:\n",
    "    print(result_df)\n",
    "    print(f\"Mean accuracy: {result_df['accuracy'].mean()}, Min accuracy: {result_df['accuracy'].min()}, Max accuracy: {result_df['accuracy'].max()} Total fit time: {result_df['fit_time'].sum()}, Total predict time: {result_df['predict_time'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = {'Label': test_labels,\n",
    "        'Prediction': predictions}\n",
    " \n",
    "# Create DataFrame\n",
    "pred_df = pd.DataFrame(pred_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person 9 complete\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "test_labels = np.array([])\n",
    "predictions = np.array([])\n",
    "\n",
    "for index, windows in enumerate(windows_all_movements):\n",
    "\n",
    "    if index == 9:\n",
    "        labels = labels_all_movements[index]\n",
    "        groups = groups_all_movements[index]\n",
    "\n",
    "        logo = LeaveOneGroupOut()\n",
    "\n",
    "        for train, test in logo.split(windows, labels, groups=groups):\n",
    "\n",
    "            test_x = np.take(windows, test, 0)\n",
    "            test_y = np.take(labels, test, 0)\n",
    "\n",
    "            y_pred = classifier.predict(test_x)\n",
    "\n",
    "            accuracy = accuracy_score(test_y, y_pred)\n",
    "            \n",
    "            # print(score)\n",
    "            row = [index, accuracy]\n",
    "            data_list.append(row)\n",
    "\n",
    "            test_labels = np.concatenate((test_labels, test_y))\n",
    "            predictions = np.concatenate((predictions, y_pred))\n",
    "\n",
    "        print(f\"Person {index} complete\")\n",
    "\n",
    "result_df = pd.DataFrame(data_list, columns =['index', 'accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.932203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0.922078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.922018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.918182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.965517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>0.934156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.946970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.949686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.964029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  accuracy\n",
       "0      9  0.932203\n",
       "1      9  0.922078\n",
       "2      9  0.922018\n",
       "3      9  0.918182\n",
       "4      9  0.965517\n",
       "5      9  0.934156\n",
       "6      9  0.941176\n",
       "7      9  0.946970\n",
       "8      9  0.949686\n",
       "9      9  0.964029"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = {'Label': test_labels,\n",
    "        'Prediction': predictions}\n",
    " \n",
    "# Create DataFrame\n",
    "pred_df = pd.DataFrame(pred_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
